{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56e45666",
   "metadata": {},
   "source": [
    "\n",
    "** Cell type : TextRead ** \n",
    "\n",
    "\n",
    "# Problem 2 : Learning Multiclass Bayes Classifiers from data with Max. Likeli.\n",
    "\n",
    "Derive Bayes classifiers under assumptions below, and use ML estimators to compute and return the results on a test set. The $4\\times 4$ loss matrix giving the loss incurred for predicting $i$ when truth is $j$ is below.\n",
    "\n",
    "$L=\\begin{bmatrix} 0 &1 & 2& 3\\\\ 1 &0 & 1& 2\\\\ 2 &1 & 0& 1\\\\ 3 &2 & 1& 0 \\end{bmatrix}$ \n",
    "\n",
    "2a) Assume $X|Y=a$ is distributed as Normal with mean $\\mu_a$ and variance $I$.\n",
    "\n",
    "2b) Assume $X|Y=a$ is distributed as Normal with mean $\\mu_a$ and variance $\\Sigma$.\n",
    "\n",
    "2c) Assume $X|Y=a$ is distributed as Normal with mean $\\mu_a$ and variance $\\Sigma_a$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ccb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell type : CodeWrite\n",
    "# Fill in functions in this cell\n",
    "\n",
    "\n",
    "def Bayes2a(X_train, Y_train, X_test):\n",
    "    \"\"\" Give Bayes classifier prediction for test instances \n",
    "    using assumption 2a.\n",
    "\n",
    "    Arguments:\n",
    "    X_train: numpy array of shape (n,d)\n",
    "    Y_train: {1,2,3,4} numpy array of shape (n,)\n",
    "    X_test : numpy array of shape (m,d)\n",
    "\n",
    "    Returns:\n",
    "    Y_test_pred : {1,2,3,4} numpy array of shape (m,)\n",
    "    \n",
    "    \"\"\"\n",
    "    L = np.array([[0,1,2,3],[1,0,1,2],[2,1,0,1],[3,2,1,0]])\n",
    "    \n",
    "    y = [Y_train[Y_train==i] for i in range(1,5)]\n",
    "\n",
    "    x = [X_train[Y_train==i,:] for i in range(1,5)]\n",
    "\n",
    "    mean = [np.mean(x[i],axis=0) for i in range(4)]\n",
    "    \n",
    "    prob = [len(y[i])/len(Y_train) for i in range(4)]\n",
    "    \n",
    "    Y_Pred = np.zeros(np.shape(X_test)[0])\n",
    "    for i in range(len(X_test)):\n",
    "        etax = np.zeros(4)\n",
    "        for k in range(4):\n",
    "            etax[k] = prob[k]*gauss(X_test[i], mean[k])\n",
    "        etaxL = np.matmul(etax,L)\n",
    "        Y_Pred[i] = np.argmin(etaxL) + 1\n",
    "\n",
    "    return Y_Pred\n",
    "\n",
    "def gauss(x, mean):\n",
    "    exponent = -0.5*(np.linalg.norm(x-mean)**2)  \n",
    "        \n",
    "    return np.exp(exponent)\n",
    "            \n",
    "def multivariate_normal(x, mean, covariance_matrix):\n",
    "    \"\"\"\n",
    "    Calculate the PDF of a multivariate normal distribution at point x.\n",
    "\n",
    "    Parameters:\n",
    "    - x: Point at which to evaluate the PDF.\n",
    "    - mean: Mean vector of the distribution.\n",
    "    - covariance_matrix: Covariance matrix of the distribution.\n",
    "\n",
    "    Returns:\n",
    "    - pdf_value: Value of the PDF at the specified point.\n",
    "    \"\"\"\n",
    "    k = len(mean)\n",
    "    det_cov = np.linalg.det(covariance_matrix)**0.5\n",
    "    inv_cov = np.linalg.inv(covariance_matrix)\n",
    "    prefactor = 1 / ((2 * np.pi) ** (k / 2) * np.sqrt(det_cov))\n",
    "    \n",
    "    pdf_values = np.zeros(x.shape[0])\n",
    "    for i in range(x.shape[0]):\n",
    "        diff = x[i] - mean\n",
    "        exponent = -0.5 * np.matmul(np.matmul(diff, inv_cov), diff.T)\n",
    "        pdf_value = prefactor * np.exp(exponent)\n",
    "        pdf_values[i] = pdf_value\n",
    "    \n",
    "    return pdf_values\n",
    "\n",
    "\n",
    "def Bayes2b(X_train, Y_train, X_test):\n",
    "    \"\"\" Give Bayes classifier prediction for test instances \n",
    "    using assumption 2b.\n",
    "\n",
    "    Arguments:\n",
    "    X_train: numpy array of shape (n,d)\n",
    "    Y_train: {1,2,3,4} numpy array of shape (n,)\n",
    "    X_test : numpy array of shape (m,d)\n",
    "\n",
    "    Returns:\n",
    "    Y_test_pred : {1,2,3,4} numpy array of shape (m,)\n",
    "    \n",
    "    \"\"\"\n",
    "    L = np.array([[0,1,2,3],[1,0,1,2],[2,1,0,1],[3,2,1,0]])\n",
    "    \n",
    "    y = [Y_train[Y_train==i] for i in range(1,5)]\n",
    "\n",
    "    x = [X_train[Y_train==i,:] for i in range(1,5)]\n",
    "    \n",
    "    mean = [np.mean(x[i],axis=0) for i in range(4)]\n",
    "    \n",
    "    prob = [len(y[i])/len(Y_train) for i in range(4)]\n",
    "    \n",
    "    cov = [np.cov(x[i], rowvar = False, bias = True) for i in range(4)]\n",
    "    \n",
    "    cov_avg = (cov[0] + cov[1] + cov[2] + cov[3])/2.0\n",
    "    \n",
    "    pdf_values = [multivariate_normal(X_test, mean[i], cov_avg) for i in range(4)]\n",
    "    \n",
    "    sum_pdf = np.zeros(X_test.shape[0])\n",
    "    for i in range(4):\n",
    "        sum_pdf = sum_pdf + pdf_values[i]\n",
    "    eta = np.array([(pdf_values[i]*prob[i])/sum_pdf for i in range(4)])\n",
    "    \n",
    "    etaL = np.matmul(eta.T,L)\n",
    "    \n",
    "    Y_test_pred = np.argmin(etaL, axis = 1) + np.ones(X_test.shape[0])\n",
    "    \n",
    "    return Y_test_pred\n",
    "    \n",
    "    \n",
    "\n",
    "def Bayes2c(X_train, Y_train, X_test):\n",
    "    \"\"\" Give Bayes classifier prediction for test instances \n",
    "    using assumption 2c.\n",
    "\n",
    "    Arguments:\n",
    "    X_train: numpy array of shape (n,d)\n",
    "    Y_train: {1,2,3,4} numpy array of shape (n,)\n",
    "    X_test : numpy array of shape (m,d)\n",
    "\n",
    "    Returns:\n",
    "    Y_test_pred : {1,2,3,4} numpy array of shape (m,)\n",
    "    \n",
    "    \"\"\"\n",
    "    L = np.array([[0,1,2,3],[1,0,1,2],[2,1,0,1],[3,2,1,0]])\n",
    "    \n",
    "    y = [Y_train[Y_train==i] for i in range(1,5)]\n",
    "\n",
    "    x = [X_train[Y_train==i,:] for i in range(1,5)]\n",
    "    \n",
    "    mean = [np.mean(x[i],axis=0) for i in range(4)]\n",
    "    \n",
    "    prob = [len(y[i])/len(Y_train) for i in range(4)]\n",
    "    \n",
    "    cov = [np.cov(x[i], rowvar = False, bias = True) for i in range(4)]\n",
    "    \n",
    "    cov_avg = (cov[0] + cov[1] + cov[2] + cov[3])/2.0\n",
    "    \n",
    "    pdf_values = [multivariate_normal(X_test, mean[i], cov[i]) for i in range(4)]\n",
    "    \n",
    "    sum_pdf = np.zeros(X_test.shape[0])\n",
    "    for i in range(4):\n",
    "        sum_pdf = sum_pdf + pdf_values[i]\n",
    "    eta = np.array([(pdf_values[i]*prob[i])/sum_pdf for i in range(4)])\n",
    "    \n",
    "    etaL = np.matmul(eta.T,L)\n",
    "    \n",
    "    Y_test_pred = np.argmin(etaL, axis = 1) + np.ones(X_test.shape[0])\n",
    "    \n",
    "    return Y_test_pred\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5198415",
   "metadata": {},
   "source": [
    "**Cell type : TextRead**\n",
    "\n",
    "# Problem 2\n",
    "\n",
    "2d) Run the above three algorithms (Bayes2a,2b and 2c), for the two datasets given (dataset2_1.npz, dataset2_2.npz) in the cell below.\n",
    "\n",
    "In the next CodeWrite cell, Plot all the classifiers (3 classification algos on 2 datasets = 6 plots) on a 2d plot (color the 4 areas classified as 1,2,3 and 4 differently). Add the training data points also on the plot. Plots to be organised as follows: One plot for each dataset, with three subplots in each for the three classifiers. Label the 6 plots appropriately. \n",
    "\n",
    "In the next Textwrite cell, summarise your observations regarding the six learnt classifiers. Give the *expected loss* (use the Loss matrix given in the problem.) of the three classifiers on the two datasets (use X_test and Y_test) as 2x3 table, with appropriately named rows and columns. Also, give the 4x4 confusion matrix of the final classifier for all three algorithms and both datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e398f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell type : CodeWrite\n",
    "# write the code for loading the data, running the three algos, and plotting here. \n",
    "# (Use the functions written previously.)\n",
    "\n",
    "data2_1 = np.load('dataset2_1.npz')\n",
    "X_train, Y_train, X_test, Y_test = data2_1['arr_0'],data2_1['arr_1'],data2_1['arr_2'],data2_1['arr_3']\n",
    "Y_pred_21a = Bayes2a(X_train,Y_train,X_test)\n",
    "Y_pred_21b = Bayes2b(X_train,Y_train,X_test)\n",
    "Y_pred_21c = Bayes2c(X_train,Y_train,X_test)\n",
    "X_min = np.min(X_train,axis=0)\n",
    "X_max = np.max(X_train,axis=0)\n",
    "L = np.array([[0,1,2,3],[1,0,1,2],[2,1,0,1],[3,2,1,0]])\n",
    "\n",
    "\n",
    "loss = L[Y_test.astype(int)-1,Y_pred_21a.astype(int)-1]\n",
    "loss = np.sum(loss,axis=0)*1.0/len(Y_test)\n",
    "loss = L[Y_test.astype(int)-1,Y_pred_21b.astype(int)-1]\n",
    "loss = sum(loss)*1.0/len(Y_test)\n",
    "loss = L[Y_test.astype(int)-1,Y_pred_21c.astype(int)-1]\n",
    "loss = sum(loss)*1.0/len(Y_test)\n",
    "\n",
    "\n",
    "\n",
    "X,Y = np.meshgrid(np.arange(X_min[0]-0.5,X_max[0]+0.5,0.1),np.arange(X_min[1]-0.5,X_max[1]+0.5,0.1))\n",
    "test_samples= np.concatenate([X.reshape(-1,1),Y.reshape(-1,1)],axis=1)\n",
    "Za = Bayes2a(X_train,Y_train,test_samples)\n",
    "Zb = Bayes2b(X_train,Y_train,test_samples)\n",
    "Zc = Bayes2c(X_train,Y_train,test_samples)\n",
    "\n",
    "\n",
    "plt.figure(0)\n",
    "f, (ax1,ax2,ax3) = plt.subplots(1,3,sharex=False,sharey=True,figsize=(15,5))\n",
    "ax1.contourf(X,Y,Za.reshape(X.shape),colors=['#ff796c','#5ca904','#fdaa48','#75bbfd']) \n",
    "ax1.scatter(X_train[Y_train==1][:,0],X_train[Y_train==1][:,1],s=2,c='r',label='Class 1')\n",
    "ax1.scatter(X_train[Y_train==2][:,0],X_train[Y_train==2][:,1],s=2,c='#f8481c',label='Class 2')\n",
    "ax1.scatter(X_train[Y_train==3][:,0],X_train[Y_train==3][:,1],s=2,c='g',label='Class 3')\n",
    "ax1.scatter(X_train[Y_train==4][:,0],X_train[Y_train==4][:,1],s=2,c='b',label='Class 4')\n",
    "ax1.set_title('Bayes2a classifier on dataset2_1')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(r'$x_{1}\\rightarrow$',size=15)\n",
    "ax1.set_ylabel(r'$x_{2}\\rightarrow$',size=15)\n",
    "\n",
    "ax2.contourf(X,Y,Zb.reshape(X.shape),colors=['#ff796c','#5ca904','#fdaa48','#75bbfd'])\n",
    "ax2.scatter(X_train[Y_train==1][:,0],X_train[Y_train==1][:,1],s=2,c='r',label='Class 1')\n",
    "ax2.scatter(X_train[Y_train==2][:,0],X_train[Y_train==2][:,1],s=2,c='#f8481c',label='Class 2')\n",
    "ax2.scatter(X_train[Y_train==3][:,0],X_train[Y_train==3][:,1],s=2,c='g',label='Class 3')\n",
    "ax2.scatter(X_train[Y_train==4][:,0],X_train[Y_train==4][:,1],s=2,c='b',label='Class 4')\n",
    "ax2.set_title('Bayes2b classifier on dataset2_1')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel(r'$x_{1}\\rightarrow$',size=15)\n",
    "ax2.set_ylabel(r'$x_{2}\\rightarrow$',size=15)\n",
    "\n",
    "ax3.contourf(X,Y,Zc.reshape(X.shape),colors=['#ff796c','#5ca904','#fdaa48','#75bbfd'])\n",
    "ax3.scatter(X_train[Y_train==1][:,0],X_train[Y_train==1][:,1],s=2,c='r',label='Class 1')\n",
    "ax3.scatter(X_train[Y_train==2][:,0],X_train[Y_train==2][:,1],s=2,c='#f8481c',label='Class 2')\n",
    "ax3.scatter(X_train[Y_train==3][:,0],X_train[Y_train==3][:,1],s=2,c='g',label='Class 3')\n",
    "ax3.scatter(X_train[Y_train==4][:,0],X_train[Y_train==4][:,1],s=2,c='b',label='Class 4')\n",
    "ax3.set_title('Bayes2c classifier on dataset2_1')\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(r'$x_{1}\\rightarrow$',size=15)\n",
    "ax3.set_ylabel(r'$x_{2}\\rightarrow$',size=15)\n",
    "plt.show()\n",
    "\n",
    "data2_2 = np.load('dataset2_2.npz')\n",
    "X_train, Y_train, X_test, Y_test = data2_2['arr_0'],data2_2['arr_1'],data2_2['arr_2'],data2_2['arr_3']\n",
    "Y_pred_22a = Bayes2a(X_train,Y_train,X_test)\n",
    "Y_pred_22b = Bayes2b(X_train,Y_train,X_test)\n",
    "Y_pred_22c = Bayes2c(X_train,Y_train,X_test)\n",
    "X_min = min(X_train[:,0]),min(X_train[:,1])\n",
    "X_max = max(X_train[:,0]),max(X_train[:,1])\n",
    "\n",
    "\n",
    "loss = L[Y_test.astype(int)-1,Y_pred_22a.astype(int)-1]\n",
    "loss = np.sum(loss,axis=0)*1.0/len(Y_test)\n",
    "loss = L[Y_test.astype(int)-1,Y_pred_22b.astype(int)-1]\n",
    "loss = sum(loss)*1.0/len(Y_test)\n",
    "loss = L[Y_test.astype(int)-1,Y_pred_22c.astype(int)-1]\n",
    "loss = sum(loss)*1.0/len(Y_test)\n",
    "\n",
    "\n",
    "X,Y = np.meshgrid(np.arange(X_min[0]-0.5,X_max[0]+0.5,0.1),np.arange(X_min[1]-0.5,X_max[1]+0.5,0.1))\n",
    "test_samples= np.concatenate([X.reshape(-1,1),Y.reshape(-1,1)],axis=1)\n",
    "Za = Bayes2a(X_train,Y_train,test_samples)\n",
    "Zb = Bayes2b(X_train,Y_train,test_samples)\n",
    "Zc = Bayes2c(X_train,Y_train,test_samples)\n",
    "\n",
    "plt.figure(1)\n",
    "f, (ax1,ax2,ax3) = plt.subplots(1,3,sharex=False,sharey=True,figsize=(15,5))\n",
    "ax1.contourf(X,Y,Za.reshape(X.shape),colors=['#ff796c','#5ca904','#fdaa48','#75bbfd'])\n",
    "ax1.scatter(X_train[Y_train==1][:,0],X_train[Y_train==1][:,1],s=2,c='r',label='Class 1')\n",
    "ax1.scatter(X_train[Y_train==2][:,0],X_train[Y_train==2][:,1],s=2,c='#f8481c',label='Class 2')\n",
    "ax1.scatter(X_train[Y_train==3][:,0],X_train[Y_train==3][:,1],s=2,c='g',label='Class 3')\n",
    "ax1.scatter(X_train[Y_train==4][:,0],X_train[Y_train==4][:,1],s=2,c='b',label='Class 4')\n",
    "ax1.set_title('Bayes2a classifier on dataset2_2')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel(r'$x_{1}\\rightarrow$',size=15)\n",
    "ax1.set_ylabel(r'$x_{2}\\rightarrow$',size=15)\n",
    "\n",
    "ax2.contourf(X,Y,Zb.reshape(X.shape),colors=['#ff796c','#5ca904','#fdaa48','#75bbfd'])\n",
    "ax2.scatter(X_train[Y_train==1][:,0],X_train[Y_train==1][:,1],s=2,c='r',label='Class 1')\n",
    "ax2.scatter(X_train[Y_train==2][:,0],X_train[Y_train==2][:,1],s=2,c='#f8481c',label='Class 2')\n",
    "ax2.scatter(X_train[Y_train==3][:,0],X_train[Y_train==3][:,1],s=2,c='g',label='Class 3')\n",
    "ax2.scatter(X_train[Y_train==4][:,0],X_train[Y_train==4][:,1],s=2,c='b',label='Class 4')\n",
    "ax2.set_title('Bayes2b classifier on dataset2_2')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel(r'$x_{1}\\rightarrow$',size=15)\n",
    "ax2.set_ylabel(r'$x_{2}\\rightarrow$',size=15)\n",
    "ax3.contourf(X,Y,Zc.reshape(X.shape),colors=['#ff796c','#5ca904','#fdaa48','#75bbfd'])\n",
    "ax3.scatter(X_train[Y_train==1][:,0],X_train[Y_train==1][:,1],s=2,c='r',label='Class 1')\n",
    "ax3.scatter(X_train[Y_train==2][:,0],X_train[Y_train==2][:,1],s=2,c='#f8481c',label='Class 2')\n",
    "ax3.scatter(X_train[Y_train==3][:,0],X_train[Y_train==3][:,1],s=2,c='g',label='Class 3')\n",
    "ax3.scatter(X_train[Y_train==4][:,0],X_train[Y_train==4][:,1],s=2,c='b',label='Class 4')\n",
    "ax3.set_title('Bayes2c classifier on dataset2_2')\n",
    "ax3.legend()\n",
    "ax3.set_xlabel(r'$x_{1}\\rightarrow$',size=15)\n",
    "ax3.set_ylabel(r'$x_{2}\\rightarrow$',size=15)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
